{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4CbPPVDM2iL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "XGBoost Classification Model\n",
        "============================\n",
        "\n",
        "This script was developed as part of an undergraduate thesis project.\n",
        "\n",
        "The objective of this work is to apply XGBoost for classification tasks\n",
        "with proper data preprocessing, feature selection, class imbalance handling,\n",
        "and hyperparameter tuning.\n",
        "\n",
        "Notes:\n",
        "- Dataset paths are placeholders.\n",
        "- Original datasets are confidential and not included.\n",
        "- This code is shared for academic and portfolio purposes only.\n",
        "\"\"\"\n",
        "\n",
        "# =========================\n",
        "# IMPORT LIBRARIES\n",
        "# =========================\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    StratifiedShuffleSplit,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# =========================\n",
        "# STRATIFIED SPLIT FUNCTION\n",
        "# =========================\n",
        "def stratified_split(X, y, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Perform stratified train-test split to ensure\n",
        "    class distribution consistency.\n",
        "    \"\"\"\n",
        "    sss = StratifiedShuffleSplit(\n",
        "        n_splits=1,\n",
        "        test_size=test_size,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    for train_idx, test_idx in sss.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA (PLACEHOLDER)\n",
        "# =========================\n",
        "# NOTE:\n",
        "# Replace this path with your own dataset location.\n",
        "# Original dataset is confidential and not included.\n",
        "DATA_PATH = \"data/dataset.xlsx\"\n",
        "\n",
        "data = pd.read_excel(DATA_PATH)\n",
        "\n",
        "# Drop unnecessary columns if present\n",
        "data = data.drop(\n",
        "    columns=[\"Measurement Date\", \"Measurement Time\"],\n",
        "    errors=\"ignore\"\n",
        ")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# LABEL ENCODING\n",
        "# =========================\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"label_encoded\"] = label_encoder.fit_transform(data[\"label\"])\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FEATURE SELECTION\n",
        "# =========================\n",
        "FEATURE_COLUMNS = [\n",
        "    \"Irradiance\",\n",
        "    \"Temperature Thermocouple 2\",\n",
        "    \"Pmax\",\n",
        "    \"Vmpp\",\n",
        "    \"Impp\",\n",
        "    \"Voc\",\n",
        "    \"Isc\"\n",
        "]\n",
        "\n",
        "X = data[FEATURE_COLUMNS]\n",
        "y = data[\"label_encoded\"]\n",
        "\n",
        "\n",
        "# =========================\n",
        "# TRAIN-TEST SPLIT\n",
        "# =========================\n",
        "X_train, X_test, y_train, y_test = stratified_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Total samples       : {len(data)}\")\n",
        "print(f\"Training samples    : {len(X_train)}\")\n",
        "print(f\"Testing samples     : {len(X_test)}\")\n",
        "\n",
        "baseline_accuracy = y_test.value_counts(normalize=True).max()\n",
        "print(f\"Baseline Accuracy   : {baseline_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# SCALING\n",
        "# =========================\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FEATURE SELECTION (ANOVA)\n",
        "# =========================\n",
        "selector = SelectKBest(score_func=f_classif, k=\"all\")\n",
        "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_selected = selector.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# HANDLE CLASS IMBALANCE\n",
        "# =========================\n",
        "sample_weights = compute_sample_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    y=y_train\n",
        ")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# XGBOOST + RANDOM SEARCH\n",
        "# =========================\n",
        "param_dist = {\n",
        "    \"n_estimators\": [100, 200],\n",
        "    \"max_depth\": [3, 4, 5],\n",
        "    \"learning_rate\": [0.001, 0.005, 0.01],\n",
        "    \"subsample\": [0.6, 0.7, 0.8, 0.9],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 0.9],\n",
        "    \"min_child_weight\": [2, 3, 4],\n",
        "    \"gamma\": [0, 0.1],\n",
        "    \"reg_alpha\": [0, 3],   # L1 regularization\n",
        "    \"reg_lambda\": [0, 5]   # L2 regularization\n",
        "}\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    tree_method=\"hist\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring=\"f1_weighted\",\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "random_search.fit(\n",
        "    X_train_selected,\n",
        "    y_train,\n",
        "    sample_weight=sample_weights\n",
        ")\n",
        "\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "\n",
        "# =========================\n",
        "# EVALUATION (TEST SET)\n",
        "# =========================\n",
        "y_pred = best_model.predict(X_test_selected)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "\n",
        "print(\"\\nBest Parameters:\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"Test Accuracy : {accuracy:.4f}\")\n",
        "print(f\"Test F1 Score : {f1:.4f}\")\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FEATURE IMPORTANCE\n",
        "# =========================\n",
        "importance = best_model.feature_importances_\n",
        "feature_names = selector.get_feature_names_out(FEATURE_COLUMNS)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_names, importance)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Features\")\n",
        "plt.title(\"XGBoost Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# =========================\n",
        "# CONFUSION MATRIX (TEST)\n",
        "# =========================\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_,\n",
        "    cbar=False\n",
        ")\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix - Test Dataset\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nProgram finished successfully.\")\n"
      ]
    }
  ]
}