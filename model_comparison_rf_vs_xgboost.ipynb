{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Comparison: Random Forest vs XGBoost\n",
        "\n",
        "This notebook compares the performance of Random Forest\n",
        "and XGBoost classification models developed for the\n",
        "undergraduate thesis project.\n"
      ],
      "metadata": {
        "id": "MsCI2-M0Us7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load dataset (local, not included in repository)\n",
        "file_path = r'C:\\Users\\lenovo\\Downloads\\Data\\combined_with_labels.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "data = data.drop(\n",
        "    columns=['Measurement Date', 'Measurement Time'],\n",
        "    errors='ignore'\n",
        ")\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['label_encoded'] = label_encoder.fit_transform(data['label'])\n",
        "\n",
        "X = data[\n",
        "    [\n",
        "        'Irradiance',\n",
        "        'Temperature Thermocouple 2',\n",
        "        'Pmax',\n",
        "        'Vmpp',\n",
        "        'Impp',\n",
        "        'Voc',\n",
        "        'Isc'\n",
        "    ]\n",
        "]\n",
        "y = data['label_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=None,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred = rf_model.predict(X_test)\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.01,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    objective='multi:softmax',\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "xgb_pred = xgb_model.predict(X_test)\n",
        "\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'XGBoost'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, rf_pred),\n",
        "        accuracy_score(y_test, xgb_pred)\n",
        "    ],\n",
        "    'F1 Score (Weighted)': [\n",
        "        f1_score(y_test, rf_pred, average='weighted'),\n",
        "        f1_score(y_test, xgb_pred, average='weighted')\n",
        "    ]\n",
        "})\n",
        "\n",
        "results\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix(y_test, rf_pred),\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_,\n",
        "    ax=axes[0],\n",
        "    cbar=False\n",
        ")\n",
        "axes[0].set_title('Random Forest')\n",
        "\n",
        "sns.heatmap(\n",
        "    confusion_matrix(y_test, xgb_pred),\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Greens',\n",
        "    xticklabels=label_encoder.classes_,\n",
        "    yticklabels=label_encoder.classes_,\n",
        "    ax=axes[1],\n",
        "    cbar=False\n",
        ")\n",
        "axes[1].set_title('XGBoost')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "rf_importance = rf_model.feature_importances_\n",
        "xgb_importance = xgb_model.feature_importances_\n",
        "\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Random Forest': rf_importance,\n",
        "    'XGBoost': xgb_importance\n",
        "})\n",
        "\n",
        "importance_df.set_index('Feature').plot(\n",
        "    kind='bar',\n",
        "    figsize=(10, 6)\n",
        ")\n",
        "\n",
        "plt.title('Feature Importance Comparison')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nfy4hGivU6-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "Both Random Forest and XGBoost demonstrate strong performance\n",
        "for the classification task.\n",
        "\n",
        "XGBoost shows improved performance on complex patterns,\n",
        "while Random Forest provides more interpretable feature importance.\n"
      ],
      "metadata": {
        "id": "9cjo7jYaVUz_"
      }
    }
  ]
}